# Alternatives-to-reporting-a-p-value-the-case-of-a-contingency-table

The details of the codeset and plots are included in the attached Microsoft Word Document (.docx) file in this repository. 
You need to view the file in "Read Mode" to see the contents properly after downloading the same.

A Brief Introduction
=======================

with collaborators about the merits of reporting p-values, particularly in the context of pilot studies or exploratory analysis. Over the past several years, the American Statistical Association has made several strong statements about the need to consider approaches that measure the strength of evidence or uncertainty that don’t necessarily rely on p-values. In 2016, the ASA attempted to clarify the proper use and interpretation of the p-value by highlighting key principles “that could improve the conduct or interpretation of quantitative science, according to widespread consensus in the statistical community.” These principles are worth noting here in case you don’t make it over to the original paper:

    1.p-values can indicate how incompatible the data are with a specified statistical model.
    2.p-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone.
    3.scientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.
    4.proper inference requires full reporting and transparency
    5.a p-value, or statistical significance, does not measure the size of an effect or the importance of a result.
    6.by itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.

More recently, the ASA elaborated on this point view, responding to those who thought the initial paper was too negative, a list of many things not to do. In this new paper, the ASA argues that “knowing what not to do with p-values is indeed necessary, but it does not suffice.” We also need to know what we should do. One of those things should be focusing on effect sizes (and some measure of uncertainty, such as a confidence or credible interval) in order to evaluate an intervention or exposure.
